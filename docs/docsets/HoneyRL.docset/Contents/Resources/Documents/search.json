{"Structs/HoneyPolicy.html#/s:7HoneyRL0A6PolicyVyACXe_tcACmcfc":{"name":"init(qValues:)","abstract":"<p>Undocumented</p>","parent_name":"HoneyPolicy"},"Structs/HoneyPolicy.html#/s:7HoneyRL6PolicyP9StateTypeQa":{"name":"StateType","parent_name":"HoneyPolicy"},"Structs/HoneyPolicy.html#/s:7HoneyRL6PolicyP10ActionTypeQa":{"name":"ActionType","parent_name":"HoneyPolicy"},"Structs/HoneyPolicy.html#/s:7HoneyRL0A6PolicyV7qValuesXevp":{"name":"qValues","abstract":"<p>Undocumented</p>","parent_name":"HoneyPolicy"},"Structs/HoneyAgent.html#/s:7HoneyRL5AgentP6reward2s12s2Sf10PolicyType_05StateH0QZ_AItF":{"name":"reward(s1:s2:)","parent_name":"HoneyAgent"},"Structs/HoneyAgent.html#/s:7HoneyRL5AgentP10PolicyTypeQa":{"name":"PolicyType","parent_name":"HoneyAgent"},"Structs/HoneyAgent.html":{"name":"HoneyAgent","abstract":"<p>An agent that can be used for honeypots. It learns episodes or requests and responses, and learns how to respond based on SARSA learning and maximimizing interaction with the attacker.</p>"},"Structs/HoneyPolicy.html":{"name":"HoneyPolicy","abstract":"<p>A policy that can be used for honeypots to respond to requests</p>"},"Protocols/SARSAAgent.html#/s:7HoneyRL10SARSAAgentPAAE5learn8episodes10PolicyTypeQzSaySayAF_05StateG0QZ_AF_06ActionG0QZtGG_tF":{"name":"learn(episodes:)","abstract":"<p>Learns a q policy given episodes using the SARSA algorithm with an empty initial policy, and alpha and gamma hyperparameters set to 1.</p>","parent_name":"SARSAAgent"},"Protocols/SARSAAgent.html#/s:7HoneyRL10SARSAAgentPAAE5learn13initialPolicy8episodes5alpha5gamma0F4TypeQzAJ_SaySayAI_05StateJ0QZ_AI_06ActionJ0QZtGGS2ftF":{"name":"learn(initialPolicy:episodes:alpha:gamma:)","abstract":"<p>Learns a q policy given episodes, an initial policy, and alpha and gamma parameters, using the SARSA algorithm</p>","parent_name":"SARSAAgent"},"Protocols/QPolicy.html#/s:7HoneyRL7QPolicyP7qValuesXevp":{"name":"qValues","abstract":"<p>Undocumented</p>","parent_name":"QPolicy"},"Protocols/QPolicy.html#/s:7HoneyRL7QPolicyPyxXe_tcxmcAaBRzlufc":{"name":"init(qValues:)","abstract":"<p>Initializes a new q policy with provided q-values</p>","parent_name":"QPolicy"},"Protocols/QPolicy.html#/s:7HoneyRL7QPolicyP8changing5state6action2tox9StateTypeQz_06ActionI0QzSftF":{"name":"changing(state:action:to:)","abstract":"<p>Initializes a new Q policy with provided Q-values</p>","parent_name":"QPolicy"},"Protocols/QPolicy.html#/s:7HoneyRL6PolicyP6choose3for10ActionTypeQzSg05StateG0Qz_tF":{"name":"choose(for:)","parent_name":"QPolicy"},"Protocols/Policy.html#/s:7HoneyRL6PolicyP9StateTypeQa":{"name":"StateType","abstract":"<p>The state type of the policy</p>","parent_name":"Policy"},"Protocols/Policy.html#/s:7HoneyRL6PolicyP10ActionTypeQa":{"name":"ActionType","abstract":"<p>The action type of the policy</p>","parent_name":"Policy"},"Protocols/Policy.html#/s:7HoneyRL6PolicyP6choose3for10ActionTypeQzSg05StateG0Qz_tF":{"name":"choose(for:)","abstract":"<p>Chooses an action given a state</p>","parent_name":"Policy"},"Protocols/Agent.html#/s:7HoneyRL5AgentP10PolicyTypeQa":{"name":"PolicyType","abstract":"<p>The policy type the agent will learn</p>","parent_name":"Agent"},"Protocols/Agent.html#/s:7HoneyRL5AgentP10RewardTypea":{"name":"RewardType","abstract":"<p>The reward type the agent uses</p>","parent_name":"Agent"},"Protocols/Agent.html#/s:7HoneyRL5AgentP10ActionTypea":{"name":"ActionType","abstract":"<p>The action type the agent uses</p>","parent_name":"Agent"},"Protocols/Agent.html#/s:7HoneyRL5AgentP9StateTypea":{"name":"StateType","abstract":"<p>The state type the agent uses</p>","parent_name":"Agent"},"Protocols/Agent.html#/s:7HoneyRL5AgentP15StateActionPaira":{"name":"StateActionPair","abstract":"<p>A state and an action</p>","parent_name":"Agent"},"Protocols/Agent.html#/s:7HoneyRL5AgentP7Episodea":{"name":"Episode","abstract":"<p>An array of state action pairs</p>","parent_name":"Agent"},"Protocols/Agent.html#/s:7HoneyRL5AgentP6reward2s12s2Sf10PolicyType_05StateH0QZ_AItF":{"name":"reward(s1:s2:)","abstract":"<p>Gets the reward for transitioning between two given states</p>","parent_name":"Agent"},"Protocols/Agent.html#/s:7HoneyRL5AgentP5learn8episodes10PolicyTypeQzSaySayAF_05StateG0QZ_AF_06ActionG0QZtGG_tF":{"name":"learn(episodes:)","abstract":"<p>Learns a policy given episodes</p>","parent_name":"Agent"},"Protocols.html#/s:7HoneyRL6ActionP":{"name":"Action","abstract":"<p>A representation of what an agent performs</p>"},"Protocols/Agent.html":{"name":"Agent","abstract":"<p>An agent learns a (possibly rewarding) policy given training data (episodes) and a reward function</p>"},"Protocols/Policy.html":{"name":"Policy","abstract":"<p>A policy chooses actions for given states</p>"},"Protocols/QPolicy.html":{"name":"QPolicy","abstract":"<p>A policy that determined by Q values - which intend to measure the quality of any given state in respect to the reward received</p>"},"Protocols/SARSAAgent.html":{"name":"SARSAAgent","abstract":"<p>An agent that uses the SARSA algorithm (state–action–reward–state–action)</p>"},"Protocols.html#/s:7HoneyRL5StateP":{"name":"State","abstract":"<p>A representation of the current situation</p>"},"Extensions/Mapping.html#/s:7HoneyRL24transformToProbabilitiesyXeycXeF":{"name":"transformToProbabilities()","abstract":"<p>Undocumented</p>","parent_name":"Mapping"},"Extensions/Mapping.html":{"name":"Mapping"},"Extensions.html":{"name":"Extensions","abstract":"<p>The following extensions are available globally.</p>"},"Protocols.html":{"name":"Protocols","abstract":"<p>The following protocols are available globally.</p>"},"Structs.html":{"name":"Structures","abstract":"<p>The following structures are available globally.</p>"}}
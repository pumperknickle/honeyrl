<!DOCTYPE html>
<html lang="en">
  <head>
    <title>SARSAAgent Protocol Reference</title>
    <link rel="stylesheet" type="text/css" href="../css/jazzy.css" />
    <link rel="stylesheet" type="text/css" href="../css/highlight.css" />
    <meta charset='utf-8'>
    <script src="../js/jquery.min.js" defer></script>
    <script src="../js/jazzy.js" defer></script>
    
  </head>
  <body>
    <a name="//apple_ref/swift/Protocol/SARSAAgent" class="dashAnchor"></a>
    <a title="SARSAAgent Protocol Reference"></a>
    <header>
      <div class="content-wrapper">
        <p><a href="../index.html">HoneyRL Docs</a> (88% documented)</p>
      </div>
    </header>
    <div class="content-wrapper">
      <p id="breadcrumbs">
        <a href="../index.html">HoneyRL Reference</a>
        <img id="carat" src="../img/carat.png" />
        SARSAAgent Protocol Reference
      </p>
    </div>
    <div class="content-wrapper">
      <nav class="sidebar">
        <ul class="nav-groups">
          <li class="nav-group-name">
            <a href="../Extensions.html">Extensions</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="../Extensions/Mapping.html">Mapping</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="../Protocols.html">Protocols</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="../Protocols.html#/s:7HoneyRL6ActionP">Action</a>
              </li>
              <li class="nav-group-task">
                <a href="../Protocols/Agent.html">Agent</a>
              </li>
              <li class="nav-group-task">
                <a href="../Protocols/CaptureAgent.html">CaptureAgent</a>
              </li>
              <li class="nav-group-task">
                <a href="../Protocols/Policy.html">Policy</a>
              </li>
              <li class="nav-group-task">
                <a href="../Protocols/QPolicy.html">QPolicy</a>
              </li>
              <li class="nav-group-task">
                <a href="../Protocols/SARSAAgent.html">SARSAAgent</a>
              </li>
              <li class="nav-group-task">
                <a href="../Protocols.html#/s:7HoneyRL5StateP">State</a>
              </li>
            </ul>
          </li>
          <li class="nav-group-name">
            <a href="../Structs.html">Structures</a>
            <ul class="nav-group-tasks">
              <li class="nav-group-task">
                <a href="../Structs/HoneyAgent.html">HoneyAgent</a>
              </li>
              <li class="nav-group-task">
                <a href="../Structs/HoneyCaptureAgent.html">HoneyCaptureAgent</a>
              </li>
              <li class="nav-group-task">
                <a href="../Structs/HoneyPolicy.html">HoneyPolicy</a>
              </li>
            </ul>
          </li>
        </ul>
      </nav>
      <article class="main-content">
        <section>
          <section class="section">
            <h1>SARSAAgent</h1>
              <div class="declaration">
                <div class="language">
                  <pre class="highlight swift"><code><span class="kd">public</span> <span class="kd">protocol</span> <span class="kt">SARSAAgent</span> <span class="p">:</span> <span class="kt"><a href="../Protocols/Agent.html">Agent</a></span> <span class="k">where</span> <span class="k">Self</span><span class="o">.</span><span class="kt">PolicyType</span> <span class="p">:</span> <span class="kt"><a href="../Protocols/QPolicy.html">QPolicy</a></span></code></pre>

                </div>
              </div>
            <p>An agent that uses the SARSA algorithm (state–action–reward–state–action)</p>

          </section>
          <section class="section task-group-section">
            <div class="task-group">
              <ul>
                <li class="item">
                  <div>
                    <code>
                    <a name="/s:7HoneyRL10SARSAAgentPAAE5learn8episodesxSaySay10PolicyType_05StateG0QZ_AF_06ActionG0QZtGG_tF"></a>
                    <a name="//apple_ref/swift/Method/learn(episodes:)" class="dashAnchor"></a>
                    <a class="token" href="#/s:7HoneyRL10SARSAAgentPAAE5learn8episodesxSaySay10PolicyType_05StateG0QZ_AF_06ActionG0QZtGG_tF">learn(episodes:)</a>
                    </code>
                      <span class="declaration-note">
                        Extension method
                      </span>
                  </div>
                  <div class="height-container">
                    <div class="pointer-container"></div>
                    <section class="section">
                      <div class="pointer"></div>
                      <div class="abstract">
                        <p>Learns a q policy given episodes using the SARSA algorithm with an empty initial policy, and alpha and gamma hyperparameters set to 0.5.</p>

                      </div>
                      <div class="declaration">
                        <h4>Declaration</h4>
                        <div class="language">
                          <p class="aside-title">Swift</p>
                          <pre class="highlight swift"><code><span class="kd">func</span> <span class="nf">learn</span><span class="p">(</span><span class="nv">episodes</span><span class="p">:</span> <span class="p">[</span><span class="kt">Episode</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="k">Self</span></code></pre>

                        </div>
                      </div>
                      <div>
                        <h4>Parameters</h4>
                        <table class="graybox">
                          <tbody>
                            <tr>
                              <td>
                                <code>
                                <em>episodes</em>
                                </code>
                              </td>
                              <td>
                                <div>
                                  <p>Training dataset of episodes</p>
                                </div>
                              </td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                      <div>
                        <h4>Return Value</h4>
                        <p>A learned policy based on q values generated by the SARSA algorithm</p>
                      </div>
                    </section>
                  </div>
                </li>
                <li class="item">
                  <div>
                    <code>
                    <a name="/s:7HoneyRL10SARSAAgentPAAE5learn8episodes5alpha5gammaxSaySay10PolicyType_05StateI0QZ_AH_06ActionI0QZtGG_S2ftF"></a>
                    <a name="//apple_ref/swift/Method/learn(episodes:alpha:gamma:)" class="dashAnchor"></a>
                    <a class="token" href="#/s:7HoneyRL10SARSAAgentPAAE5learn8episodes5alpha5gammaxSaySay10PolicyType_05StateI0QZ_AH_06ActionI0QZtGG_S2ftF">learn(episodes:alpha:gamma:)</a>
                    </code>
                      <span class="declaration-note">
                        Extension method
                      </span>
                  </div>
                  <div class="height-container">
                    <div class="pointer-container"></div>
                    <section class="section">
                      <div class="pointer"></div>
                      <div class="abstract">
                        <p>Learns a q policy given episodes, an initial policy, and alpha and gamma parameters, using the SARSA algorithm</p>

                      </div>
                      <div class="declaration">
                        <h4>Declaration</h4>
                        <div class="language">
                          <p class="aside-title">Swift</p>
                          <pre class="highlight swift"><code><span class="kd">func</span> <span class="nf">learn</span><span class="p">(</span><span class="nv">episodes</span><span class="p">:</span> <span class="p">[</span><span class="kt">Episode</span><span class="p">],</span> <span class="nv">alpha</span><span class="p">:</span> <span class="kt">Float</span><span class="p">,</span> <span class="nv">gamma</span><span class="p">:</span> <span class="kt">Float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="k">Self</span></code></pre>

                        </div>
                      </div>
                      <div>
                        <h4>Parameters</h4>
                        <table class="graybox">
                          <tbody>
                            <tr>
                              <td>
                                <code>
                                <em>initialPolicy</em>
                                </code>
                              </td>
                              <td>
                                <div>
                                  <p>The starting policy that will be modified</p>
                                </div>
                              </td>
                            </tr>
                            <tr>
                              <td>
                                <code>
                                <em>episodes</em>
                                </code>
                              </td>
                              <td>
                                <div>
                                  <p>Training dataset of episodes</p>
                                </div>
                              </td>
                            </tr>
                            <tr>
                              <td>
                                <code>
                                <em>alpha</em>
                                </code>
                              </td>
                              <td>
                                <div>
                                  <p>The learning rate determines to what extent newly acquired information overrides old information. A factor of 0 will make the agent not learn anything, while a factor of 1 would make the agent consider only the most recent information.</p>
                                </div>
                              </td>
                            </tr>
                            <tr>
                              <td>
                                <code>
                                <em>gamma</em>
                                </code>
                              </td>
                              <td>
                                <div>
                                  <p>The discount factor determines the importance of future rewards. A factor of 0 makes the agent <q>opportunistic</q> by only considering current rewards, while a factor approaching 1 will make it strive for a long-term high reward. If the discount factor meets or exceeds 1, the Q values may diverge.</p>
                                </div>
                              </td>
                            </tr>
                          </tbody>
                        </table>
                      </div>
                      <div>
                        <h4>Return Value</h4>
                        <p>A learned policy based on Q values generated by the SARSA algorithm</p>
                      </div>
                    </section>
                  </div>
                </li>
              </ul>
            </div>
          </section>
        </section>
        <section id="footer">
          <p>&copy; 2019 <a class="link" href="" target="_blank" rel="external"></a>. All rights reserved. (Last updated: 2019-12-06)</p>
          <p>Generated by <a class="link" href="https://github.com/realm/jazzy" target="_blank" rel="external">jazzy ♪♫ v0.12.0</a>, a <a class="link" href="https://realm.io" target="_blank" rel="external">Realm</a> project.</p>
        </section>
      </article>
    </div>
  </body>
</div>
</html>
